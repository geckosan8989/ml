# -*- coding: utf-8 -*-
"""fast&airf.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TAIHLF5ZILinDMAG3jxphj75RsGz_uCh
"""

import joblib
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import load_iris


data = load_iris()
x = data.data
y = data.target

model = LogisticRegression()
model.fit(x, y)

print("Dumping Model")
joblib.dump(model,"Mymodel.pkl")
print("Model Dumped")

from fastapi import FastAPI, Request
import joblib

model = joblib.load(r"Mymodel.pkl")
app = FastAPI()

@app.get("/")
def load_model():
    return "Hello model"

@app.post("/predict")
async def predict_model(request: Request):
    body = await request.json()
    data = body["data"]
    pred = model.predict([data])
    print(pred)
    return {"pred":int(pred[0])}

# postman input body
'''
{
    "data" : [25, 45, 0, 12]
}
'''

from flask import Flask, request, jsonify
import joblib

app = Flask(__name__)
model = joblib.load("Mymodel.pkl")

@app.route("/")
def hello():
    return "Hello Model"

@app.route("/predict", methods=["POST"])
def predict():
    body = request.get_json()
    data = body["data"]
    pred = model.predict([data])
    return {"pred" : int(pred[0])}


if __name__ == "__main__":
    app.run(debug=True)

#postman imput post
'''
{
    "data" : [0, 0, 0, 0]
}
'''

"""# Airflow"""

from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
import pickle

default_args = {"owner" : "himanshu", "retries": 2,
                "depend_on_past" : False
                }

dag = DAG("new", default_args=default_args,
          schedule_interval="@daily",
          start_date=datetime(2024, 1, 1))

DATA_PATH = "/home/hk/airflow/dags/data.csv"
MODEL_PATH = "/home/hk/airflow/dags/model.pkl"



def load():
    data = {
        'x' : np.random.randint(0, 100, 50),
        'y' : np.random.randint(0, 100, 50)
        }

    df = pd.DataFrame(data)
    df.to_csv(DATA_PATH, index=False)

def extract():
    df = pd.read_csv(DATA_PATH)
    x = df[['x']]
    y = df['y']
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
    model = LinearRegression()
    model.fit(x_train, y_train)
    with open(MODEL_PATH, 'wb') as f:
        pickle.dump(model, f)

def evaluate():
    df = pd.read_csv(DATA_PATH)
    x = df[['x']]
    y = df['y']
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
    with open(MODEL_PATH, 'rb') as f:
        model = pickle.load(f)
    y_pred = model.predict(x_test)
    mse = mean_squared_error(y_test, y_pred)
    r2= r2_score(y_pred, y_test)
    print(f"Mean Squared Error: {mse}")
    print(f"r2_score {r2}")
    return r2


task1 = PythonOperator(task_id="load", python_callable=load, dag=dag)
task2 = PythonOperator(task_id="extract", python_callable=extract, dag=dag)
task3 = PythonOperator(task_id="evaluate", python_callable=evaluate, dag=dag)

task1 >> task2 >> task3