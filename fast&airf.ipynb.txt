{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kq3HGfYyUxVU"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "\n",
        "data = load_iris()\n",
        "x = data.data\n",
        "y = data.target\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(x, y)\n",
        "\n",
        "print(\"Dumping Model\")\n",
        "joblib.dump(model,\"Mymodel.pkl\")\n",
        "print(\"Model Dumped\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, Request\n",
        "import joblib\n",
        "\n",
        "model = joblib.load(r\"Mymodel.pkl\")\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "def load_model():\n",
        "    return \"Hello model\"\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict_model(request: Request):\n",
        "    body = await request.json()\n",
        "    data = body[\"data\"]\n",
        "    pred = model.predict([data])\n",
        "    print(pred)\n",
        "    return {\"pred\":int(pred[0])}\n",
        "\n",
        "# postman input body\n",
        "'''\n",
        "{\n",
        "    \"data\" : [25, 45, 0, 12]\n",
        "}\n",
        "'''\n"
      ],
      "metadata": {
        "id": "hNqIBmwWU0iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "\n",
        "app = Flask(__name__)\n",
        "model = joblib.load(\"Mymodel.pkl\")\n",
        "\n",
        "@app.route(\"/\")\n",
        "def hello():\n",
        "    return \"Hello Model\"\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    body = request.get_json()\n",
        "    data = body[\"data\"]\n",
        "    pred = model.predict([data])\n",
        "    return {\"pred\" : int(pred[0])}\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True)\n",
        "\n",
        "#postman imput post\n",
        "'''\n",
        "{\n",
        "    \"data\" : [0, 0, 0, 0]\n",
        "}\n",
        "'''\n"
      ],
      "metadata": {
        "id": "p5MG9lQ7U364"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Airflow"
      ],
      "metadata": {
        "id": "aEGSjxnscJwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from airflow import DAG\n",
        "from airflow.operators.python import PythonOperator\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import pickle\n",
        "\n",
        "default_args = {\"owner\" : \"himanshu\", \"retries\": 2,\n",
        "                \"depend_on_past\" : False\n",
        "                }\n",
        "\n",
        "dag = DAG(\"new\", default_args=default_args,\n",
        "          schedule_interval=\"@daily\",\n",
        "          start_date=datetime(2024, 1, 1))\n",
        "\n",
        "DATA_PATH = \"/home/hk/airflow/dags/data.csv\"\n",
        "MODEL_PATH = \"/home/hk/airflow/dags/model.pkl\"\n",
        "\n",
        "\n",
        "\n",
        "def load():\n",
        "    data = {\n",
        "        'x' : np.random.randint(0, 100, 50),\n",
        "        'y' : np.random.randint(0, 100, 50)\n",
        "        }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(DATA_PATH, index=False)\n",
        "\n",
        "def extract():\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    x = df[['x']]\n",
        "    y = df['y']\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "    model = LinearRegression()\n",
        "    model.fit(x_train, y_train)\n",
        "    with open(MODEL_PATH, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "def evaluate():\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    x = df[['x']]\n",
        "    y = df['y']\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "    with open(MODEL_PATH, 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "    y_pred = model.predict(x_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2= r2_score(y_pred, y_test)\n",
        "    print(f\"Mean Squared Error: {mse}\")\n",
        "    print(f\"r2_score {r2}\")\n",
        "    return r2\n",
        "\n",
        "\n",
        "task1 = PythonOperator(task_id=\"load\", python_callable=load, dag=dag)\n",
        "task2 = PythonOperator(task_id=\"extract\", python_callable=extract, dag=dag)\n",
        "task3 = PythonOperator(task_id=\"evaluate\", python_callable=evaluate, dag=dag)\n",
        "\n",
        "task1 >> task2 >> task3\n",
        "\n"
      ],
      "metadata": {
        "id": "a74s25QUcIwZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}